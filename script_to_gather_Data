Gather Data from a Public API and Save to Local File
Suppose you want to gather weather data from a public API and save it to a local JSON file. Below is a Python script that accomplishes this task:


Scrape Data from a Website and Save to CSV
Suppose you want to scrape the latest news headlines from a news website and save them to a CSV file. Below is a Python script that uses the BeautifulSoup library for web scraping.

Prerequisites
Install Required Libraries:
Ensure you have the requests and beautifulsoup4 libraries installed. If not, install them using pip:

pip install requests beautifulsoup4


import requests
from bs4 import BeautifulSoup
import csv
import time

def scrape_news_headlines(url, output_file):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Find headlines (this will vary depending on the structure of the website)
        headlines = soup.find_all('h2', class_='headline')  # Example class; adjust as needed

        # Extract text and URLs from headlines
        news_data = []
        for headline in headlines:
            title = headline.get_text()
            link = headline.find('a')['href']
            news_data.append({'title': title, 'link': link})

        # Write to CSV file
        with open(output_file, 'w', newline='') as csvfile:
            fieldnames = ['title', 'link']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            writer.writeheader()
            for item in news_data:
                writer.writerow(item)
        
        print(f"Data saved to {output_file}")
    else:
        print(f"Failed to retrieve data: {response.status_code}")

def main():
    url = "https://example-news-website.com"  # Replace with the actual news website URL
    output_file = "news_headlines.csv"

    while True:
        scrape_news_headlines(url, output_file)
        time.sleep(3600)  # Wait for 1 hour before the next data gathering

if __name__ == "__main__":
    main()



Steps to Run the Script:
Replace URL:
Replace https://example-news-website.com with the actual URL of the news website you want to scrape. You may also need to adjust the HTML tags and classes used in the find_all method to match the structure of the target website.

Run the Script:
Save the script to a file, for example, news_scraper.py, and run it using Python:


Explanation:
Scrape News Headlines:
The scrape_news_headlines function sends a GET request to the specified URL, parses the HTML content using BeautifulSoup, extracts the headlines and their links, and saves them to a CSV file.

Repeat Every Hour:
The main function sets up a loop that calls the scrape_news_headlines function every hour to gather the latest headlines.

Note:
Make sure to respect the website's robots.txt file and terms of service to avoid legal issues with web scraping.
You might need to update the HTML parsing logic (find_all method) to match the specific structure of the target website. You can inspect the website's HTML using browser developer tools to find the appropriate tags and classes.
